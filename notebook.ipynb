{"cells":[{"cell_type":"markdown","metadata":{"id":"fzuf3cVHi6TS"},"source":["# Text Mining Project Work (Team 1)\n","\n","**Opinion Mining on Amazon Reviews with Logistic Regression and Deep Learning Models on top of TF-IDF Features**\n","\n","_Prof. Gianluca Moro, Prof. Giacomo Frisoni – DISI, University of Bologna_\n","\n","name.surname@unibo.it\n","\n","\n","**Bologna Business School** - Alma Mater Studiorum Università di Bologna"]},{"cell_type":"markdown","metadata":{"id":"WOBjMeN9i6TV"},"source":["## Instructions\n","- The provided exercises must be executed by the students of Team 1.\n","- At the end, the file must contain all the required results (as code cell outputs) along with all the commands necessary to reproduce them.\n","- The function of every command or group of related commands must be documented clearly and concisely.\n","- The submission deadline is March 18th, 2024.\n","- When finished, one team member will send the notebook file (having .ipynb extension) via mail (using your BBS email account) to the teacher (giacomo.frisoni@unibo.it) indicating “[BBS Teamwork] Your last names” as subject, also keeping an own copy of the file for safety.\n","- You are allowed to consult the teaching material and to search the Web for quick reference.\n","- If still in doubt about anything, ask the teacher.\n","- It is severely NOT allowed to communicate with other teams. Ask the teacher for any clarification about the exercises.\n","- Each correctly developed point counts 2/30."]},{"cell_type":"markdown","metadata":{"id":"9APLha11i6TX"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{},"source":["The following cell contains some necessary imports."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQSnHTwOi6TZ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import gzip\n","import json\n","import nltk\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import os\n","from urllib.request import urlretrieve"]},{"cell_type":"markdown","metadata":{"id":"5dIq4xWzi6Th"},"source":["Run the following to download the necessary files."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GEUzfMXAi6Ti"},"outputs":[],"source":["def download(file, url):\n","    if not os.path.exists(file):\n","        urlretrieve(url, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rw7H0NU2z9dw"},"outputs":[],"source":["download(\"Magazine_Subscriptions.json.gz\", \"https://www.dropbox.com/s/g6om8q8c8pvirw8/Magazine_Subscriptions.json.gz?dl=1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":901,"status":"ok","timestamp":1655478554373,"user":{"displayName":"Nicola Piscaglia","userId":"06169751944750633598"},"user_tz":-120},"id":"T94vizGRi6Tq","outputId":"663def10-a843-44b0-e5e3-18416eff146b"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download(\"punkt\")"]},{"cell_type":"markdown","metadata":{"id":"HefuXgg9i6Tv"},"source":["## Exercises"]},{"cell_type":"markdown","metadata":{},"source":["**1)** In the `Magazine_Subscriptions.json.gz` file, we provide a dataset composed of several reviews posted on Amazon.com about Magazine Subscriptions.\n","That file is a compressed .gzip, so you must open it using a .gzip decompression library.\n","\n","Each review is labeled with a score between 1 and 5 stars (represented by the ```overall``` feature).\n","\n","The text of each review is represented by the ```reviewText``` feature, which will be our input data along with the ```overall``` one.\n","\n","Load the dataset by putting it in a new Pandas dataframe. The data is stored as a JSON file, so you will have to use a Python package to load JSON data into a variable."]},{"cell_type":"markdown","metadata":{"id":"YejpY-z8mMEf"},"source":["**2)** Print the dataset rows number and visualize the first 5 rows."]},{"cell_type":"markdown","metadata":{"id":"hooSUzWZmRJM"},"source":["**3)** Undersample the data by `overall` feature in order to obtain a class-balanced dataset.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jbaY-6hxnY5L"},"source":["**4)** Cast the `reviewText` column to unicode string."]},{"cell_type":"markdown","metadata":{"id":"_7uRHPMRS2oj"},"source":["**5)** Choose only the attributes labeled as ```reviewText``` and ```overall``` from the dataset, and place them into a dataframe.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jLk7gkZji6UB"},"source":["**6)** Verify the distribution of the number of stars."]},{"cell_type":"markdown","metadata":{"id":"h7TL47guxDsK"},"source":["**7)** Remove from the dataframe the reviews rated with 3 stars."]},{"cell_type":"markdown","metadata":{"id":"c5JNI0iWi6UH"},"source":["**8)** Add a `label` column to the DataFrame whose value is `\"pos\"` for reviews with 4 stars, `\"very_pos\"` for 5-rated reviews, `\"neg\"` for reviews with 2 stars, and `\"very_neg\"` for 1-rated reviews."]},{"cell_type":"markdown","metadata":{"id":"gk3O4Igei6UK"},"source":["**9)** Split the dataset randomly into a training set with 70% of data and a test set with the remaining 30%, stratifying the split by the `label` variable."]},{"cell_type":"markdown","metadata":{"id":"BLD_buBZi6U6"},"source":["**10)** Create a tf.idf vector space model from training reviews excluding words appearing in less than 3 documents and using bigrams in addition to single words. Then, extract the document-term matrix for them."]},{"cell_type":"markdown","metadata":{"id":"F7Xy6Oymi6VC"},"source":["**11)** Train a logistic regression classifier on the training reviews, using the representation created above."]},{"cell_type":"markdown","metadata":{"id":"K1gSb6gDi6VM"},"source":["**12)** Verify the accuracy of the classifier on the test set."]},{"cell_type":"markdown","metadata":{"id":"lvQRHc_55w0b"},"source":["**13)** Get the model predictions and print the confusion matrix."]},{"cell_type":"markdown","metadata":{"id":"mkzzstKZpMcr"},"source":["**14)** Train a Deep Learning model of your choice (e.g., MLP, RNN) using the document-term representation built in point (10) and evaluate it on test data. Try to maximize the model accuracy."]},{"cell_type":"markdown","metadata":{"id":"JHn-cla6NrQM"},"source":["**15)** Get the predictions of this latter model and compare them with the Logistic Regression model trained in point (11) using the chi-square test at a confidence level of 95% (i.e. p-value must be <= 0.05 for models to be significantly different).\n","\n","Hint: you will need to convert the predictions of both models into integer arrays for comparison.\n","\n","\n","To calculate the p-value, you can use the provided `chi2_pval`, inputting the arrays containing the predicted labels from the two models as well as the true labels.\n","\n","```\n","chi2_pval(model1_predictions, model2_predictions, y_test)\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1654933536184,"user":{"displayName":"Nicola Piscaglia","userId":"06169751944750633598"},"user_tz":-120},"id":"deSWd-yM07Hs","outputId":"e35873ac-5c94-4515-e325-c9f611c3d7ee"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}],"source":["from scipy.stats import chi2_contingency\n","\n","def chi2_pval(p1, p2, y_test):\n","    num_classes = len(np.unique(y_test))\n","    num_instances = len(y_test)\n","\n","    model1_errors = p1 != y_test\n","    model2_errors = p2 != y_test\n","\n","    # Construct contingency table\n","    contingency_table = pd.crosstab(model1_errors, model2_errors)\n","    print(contingency_table)\n","\n","    # Calculate Chi-square test statistic and p-value\n","    q_statistic, p_value = chi2_contingency(contingency_table, correction=False)[:2]\n","\n","    return p_value"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}
